Author: Andreas Beckmann <anbe@debian.org>
Description: fix typos found by Lintian
Forwarded: https://github.com/intel/intel-graphics-compiler/issues/229

--- a/3d/common/iStdLib/CpuUtil.h
+++ b/3d/common/iStdLib/CpuUtil.h
@@ -39,7 +39,7 @@ Inline Function:
     GetCpuInstructionLevel
 
 Description:
-    Returns the highest level of IA32 intruction extensions supported by the CPU
+    Returns the highest level of IA32 instruction extensions supported by the CPU
     ( i.e. SSE, SSE2, SSE4, etc )
 
 Output:
--- a/IGC/BiFModule/Implementation/barrier.cl
+++ b/IGC/BiFModule/Implementation/barrier.cl
@@ -121,7 +121,7 @@ void SPIRV_OVERLOADABLE SPIRV_BUILTIN(Co
     }
     else  if( Execution == Subgroup )
     {
-        // nothing will be emited but we need to prevent optimization spliting control flow
+        // nothing will be emitted but we need to prevent optimization splitting control flow
         __builtin_IB_sub_group_barrier();
     }
 }
--- a/IGC/BiFModule/Implementation/group.cl
+++ b/IGC/BiFModule/Implementation/group.cl
@@ -968,7 +968,7 @@ bool SPIRV_OVERLOADABLE SPIRV_BUILTIN(Gr
         *tmp = 1;
         SPIRV_BUILTIN(ControlBarrier, _i32_i32_i32, )(Execution, 0, AcquireRelease | WorkgroupMemory); // Wait for tmp to be initialized
         if(Predicate == 0)
-            *tmp = 0; // intentional data race here, as we do not care for the value itself, rather than the fact it was overriden
+            *tmp = 0; // intentional data race here, as we do not care for the value itself, rather than the fact it was overridden
         SPIRV_BUILTIN(ControlBarrier, _i32_i32_i32, )(Execution, 0, AcquireRelease | WorkgroupMemory); // Wait for threads
         return *tmp; // Return true if none of them failed the test
     }
@@ -990,7 +990,7 @@ bool SPIRV_OVERLOADABLE SPIRV_BUILTIN(Gr
         *tmp = 0;
         SPIRV_BUILTIN(ControlBarrier, _i32_i32_i32, )(Execution, 0, AcquireRelease | WorkgroupMemory); // Wait for tmp to be initialized
         if(Predicate == 1)
-            *tmp = 1; // intentional data race here, as we do not care for the value itself, rather than the fact it was overriden
+            *tmp = 1; // intentional data race here, as we do not care for the value itself, rather than the fact it was overridden
         SPIRV_BUILTIN(ControlBarrier, _i32_i32_i32, )(Execution, 0, AcquireRelease | WorkgroupMemory);
         return *tmp; // Return true if any of them passed the test
     }
--- a/IGC/BiFModule/Languages/OpenCL/opencl_cth_released.h
+++ b/IGC/BiFModule/Languages/OpenCL/opencl_cth_released.h
@@ -3233,7 +3233,7 @@ void __attribute__((overloadable)) write
   uint4 __attribute__((overloadable)) read_imageui(read_only image3d_t image, sampler_t sampler, float4 coord, float lod);
 
 
-  // Write Image Funtions
+  // Write Image Functions
 
   // 1D writes with mipmap support
   /**
--- a/IGC/Compiler/CISACodeGen/CISABuilder.cpp
+++ b/IGC/Compiler/CISACodeGen/CISABuilder.cpp
@@ -6851,7 +6851,7 @@ namespace IGC
             else
             {
                 // Unpacking is needed from the original SIMD16 data payload to form
-                // two SIMD8 data payload by spliting the original simd16 data payload.
+                // two SIMD8 data payload by splitting the original simd16 data payload.
                 CVariable* V0, * V1;
                 uint16_t newNumElems = (uint16_t)8 * nd;
                 V0 = m_program->GetNewVariable(
--- a/IGC/Compiler/CISACodeGen/DebugInfoData.hpp
+++ b/IGC/Compiler/CISACodeGen/DebugInfoData.hpp
@@ -68,7 +68,7 @@ namespace IGC
             auto it = CVarToVISADclId.find(CVar);
             if (it == CVarToVISADclId.end())
             {
-                IGC_ASSERT_MESSAGE(false, "Didnt find VISA dcl id");
+                IGC_ASSERT_MESSAGE(false, "Didn't find VISA dcl id");
                 return 0;
             }
             if (index == 0)
--- a/IGC/Compiler/CISACodeGen/EmitVISAPass.cpp
+++ b/IGC/Compiler/CISACodeGen/EmitVISAPass.cpp
@@ -15852,7 +15852,7 @@ void EmitPass::emitMemoryFence(llvm::Ins
     }
     if (L3_Flush_RW_Data)
     {
-        // dont flush L1 if L3 is also being flushed
+        // don't flush L1 if L3 is also being flushed
         L1_Invalidate = false;
     }
 
@@ -17042,7 +17042,7 @@ void EmitPass::emitVectorBitCast(llvm::B
     if (srcEltBytes == dstEltBytes)
     {
         // This should not happen now, but generate code anyway.
-        // CISABuilder does split if there is any spliting.
+        // CISABuilder does split if there is any splitting.
 
         // Special case for: 1 element vectors to scalars
         //    %15 = bitcast <1 x i64> %4 to i64
@@ -17080,7 +17080,7 @@ void EmitPass::emitVectorBitCast(llvm::B
         IGC_ASSERT_MESSAGE((dstEltBytes % srcEltBytes) == 0, "Basic types should be power of 2");
         // Since srcEltBytes can be the second largest element type (32bit)
         // and region hstride == 1, Src will not need splitting!
-        // Only dst might need spliting.
+        // Only dst might need splitting.
         bool splitDst = (!dstUniform && (dstEltBytes * width > m_currShader->getGRFSize() * 2));
         IGC_ASSERT_MESSAGE((!splitDst || (width == 16) || (width == 32)),
             "Internal Error: Dst needs splitting only under SIMD16!");
@@ -17252,7 +17252,7 @@ void EmitPass::emitVectorBitCast(llvm::B
         CVariable* aliasSrc = m_currShader->GetNewAlias(src, m_destination->GetType(), 0, 0);
         uint32_t N = srcEltBytes / dstEltBytes;
         // Similar to dstEltBytes > srcEltBytes, dstEltBytes can be 32bit
-        // at most and dst's stride == 1, so it will not need spliting.
+        // at most and dst's stride == 1, so it will not need splitting.
         bool splitSrc = (!srcUniform && (srcEltBytes * width > m_currShader->getGRFSize() * 2));
         IGC_ASSERT_MESSAGE((!splitSrc || (width == 16) || (width == 32)),
             "Internal Error: Src needs splitting only under SIMD16!");
--- a/IGC/Compiler/CISACodeGen/PromoteInt8Type.cpp
+++ b/IGC/Compiler/CISACodeGen/PromoteInt8Type.cpp
@@ -353,7 +353,7 @@ void PromoteInt8Type::collectCandidates(
             ValueInfo* valinfo = *LI;
             Value* V = valinfo->Val;
             Instruction* I = dyn_cast<Instruction>(V);
-            IGC_ASSERT_MESSAGE(nullptr != I, "worklist entry must be an intruction!");
+            IGC_ASSERT_MESSAGE(nullptr != I, "worklist entry must be an instruction!");
             if (ExtractElementInst* EEI = dyn_cast<ExtractElementInst>(I))
             {
                 Value* VOprd = EEI->getVectorOperand();
--- a/IGC/Compiler/GenTTI.cpp
+++ b/IGC/Compiler/GenTTI.cpp
@@ -134,7 +134,7 @@ namespace llvm {
                     auto O = U->getOperand(i);
                     if (auto P = dyn_cast<PHINode>(O)) {
                         if (!L->isAuxiliaryInductionVariable(*P, SE)) {
-                            // Stop at non-auxilary IV
+                            // Stop at non-auxiliary IV
                             return false;
                         }
                     }
--- a/IGC/Compiler/LegalizationPass.cpp
+++ b/IGC/Compiler/LegalizationPass.cpp
@@ -631,7 +631,7 @@ LegalizeGVNBitCastPattern(IRBuilder<>* B
 void Legalization::visitBitCastInst(llvm::BitCastInst& I)
 {
     m_ctx->m_instrTypes.numInsts++;
-    // This is the pass that folds 2x Float into a Double replacing the bitcast intruction
+    // This is the pass that folds 2x Float into a Double replacing the bitcast instruction
     if (ConstantDataVector * vec = dyn_cast<ConstantDataVector>(I.getOperand(0)))
     {
         unsigned int nbElement = vec->getNumElements();
--- a/IGC/Compiler/Optimizer/OpenCLPasses/ExtenstionFuncs/ExtensionArgAnalysis.cpp
+++ b/IGC/Compiler/Optimizer/OpenCLPasses/ExtenstionFuncs/ExtensionArgAnalysis.cpp
@@ -19,7 +19,7 @@ using namespace IGC;
 
 // Register pass to igc-opt
 #define PASS_FLAG "igc-extension-arg-analysis"
-#define PASS_DESCRIPTION "Analyzes extenstion functions arguments"
+#define PASS_DESCRIPTION "Analyzes extension functions arguments"
 #define PASS_CFG_ONLY false
 #define PASS_ANALYSIS true
 IGC_INITIALIZE_PASS_BEGIN(ExtensionArgAnalysis, PASS_FLAG, PASS_DESCRIPTION, PASS_CFG_ONLY, PASS_ANALYSIS)
--- a/IGC/Compiler/Optimizer/OpenCLPasses/NamedBarriers/NamedBarriersResolution.cpp
+++ b/IGC/Compiler/Optimizer/OpenCLPasses/NamedBarriers/NamedBarriersResolution.cpp
@@ -118,7 +118,7 @@ bool NamedBarriersResolution::runOnModul
         // Remove not needed wrapper for Init NBarrier built-in
         for (const auto& [barrierStruct, barrierData] : m_MapInitToID)
         {
-            // We dont need any more the store instruction for nbarrier struct
+            // We don't need any more the store instruction for nbarrier struct
             for (auto user : barrierData.threadGroupNBarrierInit->users())
             {
                 if (StoreInst* storeInst = dyn_cast<StoreInst>(user))
--- a/IGC/Compiler/Optimizer/PreCompiledFuncImport.cpp
+++ b/IGC/Compiler/Optimizer/PreCompiledFuncImport.cpp
@@ -175,7 +175,7 @@ void PreCompiledFuncImport::eraseCallIns
     }
 }
 
-// This function scans intructions before emulation. It converts double-related
+// This function scans instructions before emulation. It converts double-related
 // operations (intrinsics, instructions) into ones that can be emulated. It has:
 //   1. Intrinsics
 //      Replaced some intrinsics of double operands with a known sequence that can be emulated.
--- a/IGC/Compiler/Optimizer/RectListOptimizationPass.cpp
+++ b/IGC/Compiler/Optimizer/RectListOptimizationPass.cpp
@@ -56,7 +56,7 @@ class RectListOptimizationPass : public
     typedef std::unordered_map<attribute_idx, ATTRIB_SOURCELIST_ST> atrribRectListMap;
     atrribRectListMap m_rectListPerAttrib; //rectlist info per attribute
 
-    //GS ouput instructions grouped together by all attributes
+    //GS output instructions grouped together by all attributes
     //Map => Vertex Idx ---> <attribute_idx, output_gs instruction>
     typedef std::unordered_map<attribute_idx, Instruction*> attributeInstMap;
     typedef std::vector<attributeInstMap> vetexAttribVec;
--- a/IGC/GenISAIntrinsics/Intrinsic_definitions.py
+++ b/IGC/GenISAIntrinsics/Intrinsic_definitions.py
@@ -2580,13 +2580,13 @@ Imported_Intrinsics = \
 "GenISA_TraceRayAsync": ["Raytracing: codegens to send.rta (sync bit not set)",
     [("void",                          ""),
     [("anyptr",                        "global buffer pointer"),
-     ("int",                           "Trace data: bitfield containg bvhLevel, stackID and trcCtrl")],
+     ("int",                           "Trace data: bitfield containing bvhLevel, stackID and trcCtrl")],
     "None"]],
 ####################################################################################################
 "GenISA_TraceRaySync": ["Raytracing: codegens to send.rta (with the sync bit set)",
     [("int",                           "dst is used to sync the message"),
     [("anyptr",                        "global buffer pointer"),
-     ("int",                           "Trace data: bitfield containg bvhLevel, stackID and trcCtrl")],
+     ("int",                           "Trace data: bitfield containing bvhLevel, stackID and trcCtrl")],
     "None"]],
 ####################################################################################################
 "GenISA_TraceRaySyncProceed": ["Raytracing: codegens to ShadowMemoryToSyncStack AND send.rta (sync bit set)",
@@ -2656,7 +2656,7 @@ Imported_Intrinsics = \
      ("float",                         "")],
     "None"]],
 ####################################################################################################
-"GenISA_TraceRayInlineCommittedStatus": ["Raytracing: Commited status Query for RayQuery object at index "+\
+"GenISA_TraceRayInlineCommittedStatus": ["Raytracing: Committed status Query for RayQuery object at index "+\
                                          "taken in the input",
     [("int",                           ""),
     [("int",                           "")],
--- a/IGC/Metrics/IGCMetricImpl.cpp
+++ b/IGC/Metrics/IGCMetricImpl.cpp
@@ -449,7 +449,7 @@ namespace IGCMetrics
                     func_m->set_type(IGC_METRICS::FunctionType::FUNCTION);
                     break;
                 default:
-                    IGC_ASSERT_MESSAGE(false, "Unknow Function type");
+                    IGC_ASSERT_MESSAGE(false, "Unknown Function type");
                     break;
                 }
                 map_Func.insert({ func_dbinfo , func_m });
--- a/IGC/Options/include/igc/Options/VCInternalOptions.td
+++ b/IGC/Options/include/igc/Options/VCInternalOptions.td
@@ -53,7 +53,7 @@ def freset_time_report : PlainFlag<"fres
 def print_stats : PlainFlag<"print-stats">,
   HelpText<"Print performance metrics and statistics">;
 def freset_llvm_stats : PlainFlag<"freset-llvm-stats">,
-  HelpText<"Reset perfomance metrics before compilation">;
+  HelpText<"Reset performance metrics before compilation">;
 
 def stats_file : PlainSeparate<"stats-file">,
   HelpText<"Filename to write statistics to">;
--- a/IGC/VectorCompiler/igcdeps/src/PatchTokens.cpp
+++ b/IGC/VectorCompiler/igcdeps/src/PatchTokens.cpp
@@ -113,7 +113,7 @@ buildZeDebugInfo(const CGen8CMProgram::C
   llvm::raw_string_ostream OutStream(DummyOutput);
   constexpr bool CanExitEarly = false;
   if (!IGCLLD::elf::link(LldArgs, CanExitEarly, OutStream, ErrStream)) {
-    ErrStream << "could not link debug infomation file\n";
+    ErrStream << "could not link debug information file\n";
     return {};
   }
   llvm::FileRemover Remover{OutputPath};
--- a/IGC/VectorCompiler/include/vc/GenXOpts/GenXAnalysis.h
+++ b/IGC/VectorCompiler/include/vc/GenXOpts/GenXAnalysis.h
@@ -52,7 +52,7 @@ Constant *ConstantFoldGenX(Instruction *
 Value *SimplifyGenXIntrinsic(unsigned IID, Type *RetTy, Use *ArgBegin,
                              Use *ArgEnd, const DataLayout &DL);
 
-/// Given a GenX related intruction, see if we can fold the
+/// Given a GenX related instruction, see if we can fold the
 /// result. This function tries simplification and then constant folding.
 ///
 /// If this instruction could not be simplified returns null.
--- a/IGC/VectorCompiler/lib/GenXCodeGen/GenX.td
+++ b/IGC/VectorCompiler/lib/GenXCodeGen/GenX.td
@@ -80,7 +80,7 @@ def FeatureIntDivRem32: SubtargetFeature
 def FeatureInstrAdd64: SubtargetFeature<"add64",
                                        "HasAdd64",
                                        "true",
-                                       "enable support for native add64 intruction">;
+                                       "enable support for native add64 instruction">;
 
 def FeatureInstrBitRotate: SubtargetFeature<"bitrotate",
                                            "HasBitRotate",
@@ -105,7 +105,7 @@ def FeatureHasL1ReadOnlyCache: Subtarget
 def FeatureSupressLocalMemFence: SubtargetFeature<"supress_local_mem_fence",
                                                   "HasLocalMemFenceSupress",
                                                   "true",
-                                                  "Supresses local memory fence">;
+                                                  "Suppresses local memory fence">;
 def FeatureHasPackedFloat : SubtargetFeature<"has_packed_float",
                                              "HasPackedFloat",
                                              "true",
--- a/IGC/VectorCompiler/lib/GenXCodeGen/GenXDepressurizer.cpp
+++ b/IGC/VectorCompiler/lib/GenXCodeGen/GenXDepressurizer.cpp
@@ -848,7 +848,7 @@ void GenXDepressurizer::attemptSinking(I
     //
     // ... := use(v0); // SB.Head
     //
-    // v1  := twoaddr(v0); // two-addr intruction.
+    // v1  := twoaddr(v0); // two-addr instruction.
     //
     // x <--- here this SB could be sunk to.
     //
--- a/IGC/VectorCompiler/lib/GenXCodeGen/GenXEmulate.cpp
+++ b/IGC/VectorCompiler/lib/GenXCodeGen/GenXEmulate.cpp
@@ -1840,7 +1840,7 @@ Instruction *llvm::genx::emulateI64Opera
     // If there is no explicit request to enable i64 emulation - report
     // an error
     if (NewInst && !ST->emulateLongLong() && OptStrictEmulationRequests) {
-      report_fatal_error("int_emu: target does not suport i64 types", false);
+      report_fatal_error("int_emu: target does not support i64 types", false);
     }
   }
   else if (ST->partialI64Emulation()) {
--- a/IGC/VectorCompiler/lib/GenXOpts/CMAnalysis/ConstantFoldingGenX.cpp
+++ b/IGC/VectorCompiler/lib/GenXOpts/CMAnalysis/ConstantFoldingGenX.cpp
@@ -270,7 +270,7 @@ Constant *llvm::ConstantFoldGenX(Instruc
   Constant *Folded = ConstantFoldGenXIntrinsic(
       IID, CS.getFunctionType()->getReturnType(), ConstantArgs, I, DL);
   if (Folded)
-    LLVM_DEBUG(dbgs() << "Successfully constant folded intruction to "
+    LLVM_DEBUG(dbgs() << "Successfully constant folded instruction to "
                       << *Folded << "\n");
   else
     LLVM_DEBUG(dbgs() << "Failed to constant fold instruction\n");
--- a/IGC/VectorCompiler/lib/Support/BackendConfig.cpp
+++ b/IGC/VectorCompiler/lib/Support/BackendConfig.cpp
@@ -82,7 +82,7 @@ static cl::opt<bool>
 
 static cl::opt<bool>
     DisableExtraCoalescingOpt("vc-disable-extra-coalescing", cl::Hidden,
-                              cl::desc("disable extrac coalescing"));
+                              cl::desc("disable extra coalescing"));
 
 static cl::opt<bool> DisableNonOverlappingRegionOptOpt(
     "vc-disable-non-overlapping-region-opt", cl::Hidden,
--- a/IGC/VectorCompiler/lib/Support/PassManager.cpp
+++ b/IGC/VectorCompiler/lib/Support/PassManager.cpp
@@ -298,9 +298,9 @@ void addPassImpl(PMT &PM, Pass &P, Adder
     return Adder(PM, P);
   }
   PassKind PassKindID = P.getPassKind();
-  // Extra passes are inserted independent on whether or not the pass is ommited
+  // Extra passes are inserted independent on whether or not the pass is omitted
   // to preserve numbering of passes inside them (if '*' is passed to
-  // -vc-dump-...-pass, and one occurence of a pass is ommited, the numbering of
+  // -vc-dump-...-pass, and one occurence of a pass is omitted, the numbering of
   // others would shift if addExtraPasses would not be called).
   addExtraPass<ExtraIRDumpBeforePass>(PM, PassInfo, PassKindID, Adder);
   addExtraPass<ExtraVerificationBeforePass>(PM, PassInfo, PassKindID, Adder);
@@ -308,7 +308,7 @@ void addPassImpl(PMT &PM, Pass &P, Adder
   auto PassArg = PassInfo->getPassArgument();
   auto res = DisablePass.getValue().includes(PassArg);
   if (res.first)
-    errs() << "Pass " << PassArg << res.second.str() << " is ommited\n";
+    errs() << "Pass " << PassArg << res.second.str() << " is omitted\n";
   else
     Adder(PM, P);
 
--- a/IGC/common/IntrinsicAnnotator.cpp
+++ b/IGC/common/IntrinsicAnnotator.cpp
@@ -25,7 +25,7 @@ void IntrinsicAnnotator::emitFunctionAnn
         OS << "; Function Desc: " << comments.funcDescription << "\n";
         for (auto out : comments.outputs)
         {
-            OS << "; Ouput: " << out << "\n";
+            OS << "; Output: " << out << "\n";
         }
         for (std::vector<int>::size_type i = 0; i != comments.inputs.size(); i++)
         {
--- a/IGC/common/igc_flags.h
+++ b/IGC/common/igc_flags.h
@@ -57,7 +57,7 @@ DECLARE_IGC_REGKEY(DWORD,disableIGASynta
 DECLARE_IGC_REGKEY(DWORD,disableCompaction,             false, "Disables compaction.", true)
 DECLARE_IGC_REGKEY(DWORD,TotalGRFNum,                   0,     "Total GRF used for register allocation.", false)
 DECLARE_IGC_REGKEY(DWORD,TotalGRFNum4CS,                0,     "Total GRF used for register allocation. ComputeShader only.", false)
-DECLARE_IGC_REGKEY(DWORD,ReservedRegisterNum,           0,     "Reserve regsiter number for spill cost testing.", false)
+DECLARE_IGC_REGKEY(DWORD,ReservedRegisterNum,           0,     "Reserve register number for spill cost testing.", false)
 DECLARE_IGC_REGKEY(DWORD, GRFNumToUse,                  0,     "Set the number of general registers to use (64 to totalGRFNum)", false)
 DECLARE_IGC_REGKEY(bool, ExpandPlane,                   false, "Enable pln to mad macro expansion.", false)
 DECLARE_IGC_REGKEY(bool, EnableBCR,                     false, "Enable bank conflict reduction.", true)
@@ -336,7 +336,7 @@ DECLARE_IGC_REGKEY(bool, DumpOCLProgramI
 DECLARE_IGC_REGKEY(bool, DumpPatchTokens,               false, "Enable dumping of patch tokens.", true)
 DECLARE_IGC_REGKEY(bool, DumpVariableAlias,             false, "Dump variable alias info, valid if EnableVariableAlias is on)", true)
 DECLARE_IGC_REGKEY(bool, DumpDeSSA,                     false, "dump DeSSA info into file.", true)
-DECLARE_IGC_REGKEY(bool, DumpWIA,                       false, "dump WI (uniform) infomation into files in dump directory if set to true", false)
+DECLARE_IGC_REGKEY(bool, DumpWIA,                       false, "dump WI (uniform) information into files in dump directory if set to true", false)
 DECLARE_IGC_REGKEY(bool, EnableScalarizerDebugLog,      false, "print step by step scalarizer debug info.", true)
 DECLARE_IGC_REGKEY(bool, DumpTimeStats,                 false, "Timing of translation, code generation, finalizer, etc", true)
 DECLARE_IGC_REGKEY(bool, DumpTimeStatsCoarse,           false, "Only collect/dump coarse level time stats, i.e. skip opt detail timer for now", true)
@@ -354,7 +354,7 @@ DECLARE_IGC_REGKEY(bool, UseOffsetInLoca
 DECLARE_IGC_REGKEY(bool, EnableRelocations,             false, "Setting this to 1 (true) makes IGC emit relocatable ELF with debug info", true)
 DECLARE_IGC_REGKEY(bool, EnableWriteOldFPToStack,       true,  "Setting this to 1 (true) writes the caller frame's frame-pointer to the start of callee's frame on stack, to support stack walk", false)
 DECLARE_IGC_REGKEY(bool, ZeBinCompatibleDebugging,      true,  "Setting this to 1 (true) enables embed debug info in zeBinary", true)
-DECLARE_IGC_REGKEY(bool, DebugInfoEnforceAmd64EM,       false, "Enforces elf file with the debug infomation to have eMachine set to AMD64", false)
+DECLARE_IGC_REGKEY(bool, DebugInfoEnforceAmd64EM,       false, "Enforces elf file with the debug information to have eMachine set to AMD64", false)
 DECLARE_IGC_REGKEY(bool, DebugInfoValidation,           false, "Enable optional (strict) checks to detect debug information inconsistencies", false)
 DECLARE_IGC_REGKEY(debugString, ExtraOCLOptions,        0,     "Extra options for OpenCL", true)
 DECLARE_IGC_REGKEY(debugString, ExtraOCLInternalOptions, 0,    "Extra internal options for OpenCL", true)
@@ -626,7 +626,7 @@ DECLARE_IGC_REGKEY(bool, FastCompileRA,
 DECLARE_IGC_REGKEY(bool, HybridRAWithSpill, false, "Did Hybrid RA with Spill", false)
 DECLARE_IGC_REGKEY(DWORD, StripDebugInfo, 0,
     "Strip debug info from llvm IR lowered from input to IGC ."\
-    "Possible values: 0 - dont strip, 1 - strip all, 2 - strip non-line info",
+    "Possible values: 0 - don't strip, 1 - strip all, 2 - strip non-line info",
     false)
 DECLARE_IGC_REGKEY(bool, EmitPreDefinedForAllFunctions, false, "When enabled, pre-defined variables for gid, grid, lid are emitted for all functions. This causes those functions to be inlined even when stack calls is enabled.", true)
 DECLARE_IGC_REGKEY(bool, EnableGPUFenceScopeOnSingleTileGPUs, false, "Allow the use of `GPU` fence scope on single-tile GPUs. By default the `TILE` scope is used instead of `GPU` scope on single-tile GPUs.", true)
--- a/visa/BinaryEncodingIGA.cpp
+++ b/visa/BinaryEncodingIGA.cpp
@@ -488,7 +488,7 @@ iga::SFID BinaryEncodingIGA::getSFID(con
     case vISA::SFID::TGM:       sfid = iga::SFID::TGM; break;
     case vISA::SFID::UGML:      sfid = iga::SFID::UGML; break;
     default:
-        ASSERT_USER(false, "Unknow SFID generated from vISA");
+        ASSERT_USER(false, "Unknown SFID generated from vISA");
         break;
     }
 
--- a/visa/BuildCISAIRImpl.cpp
+++ b/visa/BuildCISAIRImpl.cpp
@@ -235,7 +235,7 @@ static const WA_TABLE *CreateVisaWaTable
 // Change default values of some options according to WA_TABLE
 // The values are set before parsing any flags specified by client
 // (either within CreateVISABuilder() call or via VISABuilder interface)
-// and may be overriden by client flags
+// and may be overridden by client flags
 static void AddWAOptions(Options &options, const WA_TABLE &waTable)
 {
     if (waTable.Wa_1808850743 || waTable.Wa_1409909237)
@@ -1269,7 +1269,7 @@ static void Stitch_Compiled_Units(
             }
             else
             {
-                // src0 is dont care for indirect call as long it's not a label
+                // src0 is don't care for indirect call as long it's not a label
                 auto callInst = builder->createInternalInst(
                     fcall->getPredicate(), G4_call, nullptr, g4::NOSAT, fcall->getExecSize(),
                     fcall->getDst(), fcall->getSrc(0), fcall->getSrc(0), fcall->getOption());
@@ -1823,7 +1823,7 @@ int CISA_IR_Builder::Compile(const char*
                     // specify its binary buffer in m_cisaBinary
                     // FIXME: By this the external functions' gen-binary will be part of .isa output when
                     // calling CisaBinary::dumpToStream, and avoid the assert in dumpToStream. But when
-                    // parsing the emited .isa file, our parser may not correctly support this case.
+                    // parsing the emitted .isa file, our parser may not correctly support this case.
                     if (m_options.getOption(vISA_noStitchExternFunc) &&
                         func->getKernel()->getBoolKernelAttr(Attributes::ATTR_Extern)) {
                         m_cisaBinary->patchFunctionWithGenBinary(functionCount, func->getGenxBinarySize(),
@@ -1858,7 +1858,7 @@ int CISA_IR_Builder::Compile(const char*
 #ifndef DLL_MODE
     if (criticalMsg.str().length() > 0)
     {
-        std::cerr << "[vISA Finalizer Messsages]\n" << criticalMsg.str();
+        std::cerr << "[vISA Finalizer Messages]\n" << criticalMsg.str();
     }
 #endif //DLL_MODE
 
--- a/visa/BuildIRImpl.cpp
+++ b/visa/BuildIRImpl.cpp
@@ -173,7 +173,7 @@ void IR_Builder::bindInputDecl(G4_Declar
     dcl->setRegFile(G4_INPUT);
     unsigned int reservedGRFNum = m_options->getuInt32Option(vISA_ReservedGRFNum);
     if (regNum + dcl->getNumRows() > kernel.getNumRegTotal() - reservedGRFNum) {
-        MUST_BE_TRUE(false, "INPUT payload execeeds the regsiter number");
+        MUST_BE_TRUE(false, "INPUT payload execeeds the register number");
     }
 }
 
--- a/visa/FlowGraph.cpp
+++ b/visa/FlowGraph.cpp
@@ -1223,7 +1223,7 @@ void FlowGraph::handleExit(G4_BB* firstS
         if (!(builder->getFCPatchInfo() &&
             builder->getFCPatchInfo()->getFCComposableKernel()))
         {
-            // Dont insert EOT send for FC composable kernels
+            // Don't insert EOT send for FC composable kernels
             exitBB->addEOTSend();
         }
 
@@ -1244,7 +1244,7 @@ void FlowGraph::handleExit(G4_BB* firstS
                 if ((*lastBBIt) == retBB)
                 {
                     // This condition is BB layout dependent.
-                    // However, we dont change BB layout in JIT
+                    // However, we don't change BB layout in JIT
                     // and in case we do it in future, we
                     // will need to insert correct jumps
                     // there to preserve correctness.
--- a/visa/G4_IR.cpp
+++ b/visa/G4_IR.cpp
@@ -316,7 +316,7 @@ void G4_INST::setOpcode(G4_opcode opcd)
         G4_Inst_Table[opcd].instType == InstTypeVector)
        ) ||
         opcd == G4_label),
-        "setOpcode would change the intruction class, which is illegal.");
+        "setOpcode would change the instruction class, which is illegal.");
 
     bool resetBounds = false;
 
@@ -861,7 +861,7 @@ void G4_INST::removeUseOfInst()
     }
 }
 
-// remove the faked def-instructions in def list, which is resulted from instruction spliting
+// remove the faked def-instructions in def list, which is resulted from instruction splitting
 void G4_INST::trimDefInstList()
 {
     // trim def list
@@ -1681,7 +1681,7 @@ static G4_INST::MovType getMovType(
     // the source type only.
     if (TypeSize(srcTy) < TypeSize(dstTy)) {
         if (IS_SIGNED_INT(srcTy)) {
-            // Treat ABS as zero-extenstion.
+            // Treat ABS as zero-extension.
             if (srcMod == Mod_Abs)
                 return G4_INST::ZExt;
             // If the sign bit is 0, then zext is the same as sext.
@@ -1700,7 +1700,7 @@ static G4_INST::MovType getMovType(
     }
 
     // Otherwise, treat it as COPY they are the same in bit size.
-    // Treat ABS as zero-extenstion.
+    // Treat ABS as zero-extension.
     if (IS_SIGNED_INT(srcTy) && srcMod == Mod_Abs)
         return G4_INST::ZExt;
     return G4_INST::Copy;
@@ -2885,7 +2885,7 @@ bool G4_INST::canHoistTo(const G4_INST *
         return false;
     }
 
-    // dont hoist stack calls related variables (Arg, Retval, SP, FP)
+    // don't hoist stack calls related variables (Arg, Retval, SP, FP)
     if (defInst->getDst() && defInst->getDst()->getTopDcl())
     {
         G4_Declare* defDstDcl = defInst->getDst()->getTopDcl()->getRootDeclare();
@@ -3685,7 +3685,7 @@ void G4_INST::emitInstIds(std::ostream&
 
 //
 // Here we add a parameter symbolreg instead of use global option Options::symbolReg,
-// because we should ouput non-symbolic register when dumping dot files
+// because we should output non-symbolic register when dumping dot files
 //
 void G4_INST::emit(std::ostream& output, bool symbolreg, bool dotStyle)
 {
@@ -4953,7 +4953,7 @@ unsigned G4_DstRegRegion::computeRightBo
         else
         {
             /*
-                we need to set leftBound for pseudo intruction
+                we need to set leftBound for pseudo instruction
                 so that it creates use/def links correctly in the control flow graph between
                 cmp instruction and pseudo instruction.
                 This matters when we break up SIMD32 instruction in to two SIMD16 with H1/H2 masks.
@@ -6285,7 +6285,7 @@ int64_t G4_Imm::typecastVals(int64_t val
     }
     default:
     {
-        // Dont do float conversions
+        // Don't do float conversions
         retVal = value;
     }
     }
@@ -6523,7 +6523,7 @@ unsigned G4_SrcRegRegion::computeRightBo
         else
         {
             /*
-                we need to set leftBound for pseudo intruction
+                we need to set leftBound for pseudo instruction
                 so that it creates use/def links correctly in the control flow graph between
                 cmp instruction and pseudo instruction.
                 This matters when we break up SIMD32 instruction in to two SIMD16 with H1/H2 masks.
@@ -7289,7 +7289,7 @@ void G4_INST::setSrc(G4_Operand* opnd, u
             (srcs[3] == srcs[i] && i != 3))
         {
             // opnd is present in some other
-            // index of srcs so dont set its
+            // index of srcs so don't set its
             // inst to NULL
         }
         else
--- a/visa/GraphColor.cpp
+++ b/visa/GraphColor.cpp
@@ -321,7 +321,7 @@ void BankConflictPass::setupBankConflict
         }
     }
 
-    //In case src1 and src2 share same declare, i.e. use same regsiter
+    //In case src1 and src2 share same declare, i.e. use same register
     if (bank_num == 0 &&
         dcls[1] == dcls[2])
     {
@@ -686,7 +686,7 @@ void BankConflictPass::setupBankConflict
         }
     }
 
-    //In case (src0) src1 and src2 use same declare, i.e. use same regsiter
+    //In case (src0) src1 and src2 use same declare, i.e. use same register
     if ((dcls[0] == dcls[1]) && (dcls[1] == dcls[2]))
     {
         return;
@@ -837,7 +837,7 @@ void BankConflictPass::setupBankConflict
     }
 #endif
 
-    //In case (src0) src1 and src2 use same declare, i.e. use same regsiter
+    //In case (src0) src1 and src2 use same declare, i.e. use same register
     if (dcls[0] == dcls[2] ||
         !dcls[0] || !dcls[2])
     {
@@ -3572,7 +3572,7 @@ void Augmentation::markNonDefaultDstRgn(
     }
     else
     {
-        MUST_BE_TRUE(false, "Dont know how to handle this type of operand");
+        MUST_BE_TRUE(false, "Don't know how to handle this type of operand");
     }
 
     // Handle condMod
@@ -4457,7 +4457,7 @@ void Augmentation::buildLiveIntervals()
 void Augmentation::clearIntervalInfo()
 {
     // Clear out calculated information so that subsequent RA
-    // iterations dont have stale information
+    // iterations don't have stale information
     for (DECLARE_LIST_ITER dcl_it = kernel.Declares.begin(), end = kernel.Declares.end();
         dcl_it != end;
         dcl_it++)
@@ -4582,7 +4582,7 @@ void Augmentation::handleSIMDIntf(G4_Dec
         //
         // V33 will interfere with VCA_SAVE pseudo node.
         // It also needs to interfere with retval to
-        // ensure V33 and retval dont get same allocation.
+        // ensure V33 and retval don't get same allocation.
         // Note that if V33 is actually live after fcall
         // then graph coloring will do this for us. In this
         // case however we need to rely on augmentation.
@@ -4965,7 +4965,7 @@ void Augmentation::buildSIMDIntfDcl(G4_D
             // r[A0] = ...
             // (W) Spill ADD_SP_FL_1
             //
-            // ADDR_SP_FL_1 and FL_V10 shouldnt interfere. Without logic below, they would
+            // ADDR_SP_FL_1 and FL_V10 shouldn't interfere. Without logic below, they would
             // interfere making RA results worse.
 
             auto regVar1 = nonDefaultDcl->getRegVar();
@@ -4991,7 +4991,7 @@ void Augmentation::buildSIMDIntfDcl(G4_D
             // In above example, V1 doesnt interfere with V2 as per scalar liveness but it
             // should if the branch were divergent. For correctness we need to mark V1 and
             // V2 as interfering. Since they're never live together as per scalar liveness,
-            // they need to be handled in augmentation. This case shouldnt occur for RA tmps
+            // they need to be handled in augmentation. This case shouldn't occur for RA tmps
             // as RA generated spill/fill tmps are transient and never live-out of any BB.
             // Still adding check to be safe.
 
@@ -5498,7 +5498,7 @@ void Interference::buildInterferenceWith
 #endif
                     }
 
-                    // Build interference only for point ranges, ideally which shouldnt exist
+                    // Build interference only for point ranges, ideally which shouldn't exist
                     // These are ranges that have a def, but no use
                     if (localLR->getFirstRef(t) == localLR->getLastRef(t))
                     {
@@ -6601,7 +6601,7 @@ bool GraphColor::assignColors(ColorHeuri
     // try re-allocation of a child/parent dcl when split is enabled.
     // ignoreChildrenIntf is set to true when all children are assigned to consecutive ranges
     // and we want to get fully coalesceable assignment for parent. In such circumstance, we
-    // dont want to account for interference between parent/child since doing so cannot result
+    // don't want to account for interference between parent/child since doing so cannot result
     // in a coalesceable assignment.
     auto assignColor = [&](LiveRange* lr, bool ignoreChildrenIntf = false, bool spillAllowed = true, bool returnFalseOnFail = false)
     {
@@ -6794,7 +6794,7 @@ bool GraphColor::assignColors(ColorHeuri
                     // for first-fit register assignment track spilled live ranges
                     if (spillAllowed)
                     {
-                        // When retrying a coalesceable assignment, dont spill
+                        // When retrying a coalesceable assignment, don't spill
                         // if there is no GRF available.
                         spilledLRs.push_back(lr);
                         lr->setSpilled(true);
@@ -6828,7 +6828,7 @@ bool GraphColor::assignColors(ColorHeuri
     {
         auto lr = (*iter);
 
-        // in case child/parent was already spilled earlier, dont recolor
+        // in case child/parent was already spilled earlier, don't recolor
         if (lr->isSpilled())
             continue;
 
@@ -8879,8 +8879,8 @@ void GlobalRA::reportUndefinedUses(
 
     if (referencedDcl->getAddressed() == true)
     {
-        // Dont run analysis for addressed opnds.
-        // Specifically, we dont analyze following,
+        // Don't run analysis for addressed opnds.
+        // Specifically, we don't analyze following,
         //
         // A0 = &V1
         // r[A0] = 0 <-- V1 indirectly defined
@@ -9257,8 +9257,8 @@ void VarSplit::rangeListSpliting(VAR_RAN
         if ((*it)->leftBound > range->rightBound)
         {
             //The range item in the list is on the right of current range, insert it before the postion.
-            //Since the whole range is inserted first, all the ranges should be continous.
-            ASSERT_USER((*it)->leftBound - range->rightBound == 1, "none continous spliting happened\n");
+            //Since the whole range is inserted first, all the ranges should be continuous.
+            ASSERT_USER((*it)->leftBound - range->rightBound == 1, "none continuous splitting happened\n");
             rangeList->insert(it, range);
             return;
         }
@@ -10574,7 +10574,7 @@ int GlobalRA::coloringRegAlloc()
             {
                 if (isReRAPass())
                 {
-                    // Dont modify program if reRA pass spills
+                    // Don't modify program if reRA pass spills
                     return VISA_SPILL;
                 }
 
@@ -10957,7 +10957,7 @@ int GlobalRA::coloringRegAlloc()
             kernel.getGTPinData()->setScratchNextFree(scratchAllocation - kernel.getGTPinData()->getNumBytesScratchUse());
         }
         else {
-            // stack call functions shouldnt report any scratch usage as it is
+            // stack call functions shouldn't report any scratch usage as it is
             // kernel's responsibility to account for stack usage of entire call
             // tree.
             if (!kernel.fg.getIsStackCallFunc())
@@ -12313,7 +12313,7 @@ void GraphColor::dumpRegisterPressure()
 void GlobalRA::fixAlignment()
 {
     // Copy over alignment from G4_RegVar to GlobalRA instance
-    // Rest of RA shouldnt have to read/modify alignment of G4_RegVar
+    // Rest of RA shouldn't have to read/modify alignment of G4_RegVar
     copyAlignment();
 
     if (kernel.getSimdSize() == g4::SIMD32)
--- a/visa/GraphColor.h
+++ b/visa/GraphColor.h
@@ -754,7 +754,7 @@ namespace vISA
         // map ret location to declare for call/ret
         std::map<uint32_t, G4_Declare*> retDecls;
 
-        // store instructions that shouldnt be rematerialized.
+        // store instructions that shouldn't be rematerialized.
         std::unordered_set<G4_INST*> dontRemat;
 
         RAVarInfo &allocVar(const G4_Declare* dcl)
@@ -1377,8 +1377,8 @@ namespace vISA
         vISA::G4_Operand*    flagOpnd;
         INST_LIST_ITER inst_it;
 
-        unsigned   linearizedStart; //linearized start regsiter address
-        unsigned   linearizedEnd;   //linearized end regsiter address
+        unsigned   linearizedStart; //linearized start register address
+        unsigned   linearizedEnd;   //linearized end register address
         unsigned   leftOff;         //left offset in scratch space
         unsigned   rightOff;        //right offset in the scratch space
         unsigned   useCount;
--- a/visa/HWConformity.cpp
+++ b/visa/HWConformity.cpp
@@ -6194,7 +6194,7 @@ void HWConformity::fixBFMixedMode()
             bool changed = false;
             if (currES > nativeES)
             {
-                // No spliting needed for an inst whose execsize <= nativeES, as
+                // No splitting needed for an inst whose execsize <= nativeES, as
                 // its operand takes one GRF at most.
                 for (int i = 0, nsrc = (int)Inst->getNumSrc(); i < nsrc; ++i)
                 {
@@ -6710,7 +6710,7 @@ bool HWConformity::splitInstListForByteD
             MUST_BE_TRUE(new_iter != bb->end(), "Cannot find predicate definition function in BB.");
             new_iter++;
             G4_INST* secondHalfOp = splitInstWithByteDst(expand_op);
-            MUST_BE_TRUE(secondHalfOp, "Error in spliting instruction.");
+            MUST_BE_TRUE(secondHalfOp, "Error in splitting instruction.");
             bb->insertBefore(new_iter, secondHalfOp);
         }
     }
@@ -7049,7 +7049,7 @@ bool HWConformity::markPackedByteReferen
         }
 
         if (opnd->isDstRegRegion() &&
-            // check if the opnd has pre-assigned physical regsiter
+            // check if the opnd has pre-assigned physical register
             !(topdcl->getRegVar()->isPhyRegAssigned()) &&
             // check if the opnd is global
             !(kernel.fg.globalOpndHT.isOpndGlobal(opnd)) &&
@@ -7082,7 +7082,7 @@ bool HWConformity::markPackedByteReferen
             }
         }
         else if (opnd->isSrcRegRegion() &&
-            // check if the opnd has pre-assigned physical regsiter
+            // check if the opnd has pre-assigned physical register
             !(opnd->asSrcRegRegion()->getBase()->asRegVar()->isPhyRegAssigned()) &&
             // check if the opnd is global
             !(kernel.fg.globalOpndHT.isOpndGlobal(opnd)) &&
--- a/visa/IsaVerification.cpp
+++ b/visa/IsaVerification.cpp
@@ -1718,7 +1718,7 @@ void vISAVerifier::verifyInstructionArit
     case ISA_ADD3O:
         REPORT_INSTRUCTION(options, dstType == ISA_TYPE_UD || dstType == ISA_TYPE_D ||
             dstType == ISA_TYPE_UW || dstType == ISA_TYPE_W,
-            "%s only supports interger D/W type", ISA_Inst_Table[opcode].str);
+            "%s only supports integer D/W type", ISA_Inst_Table[opcode].str);
         break;
     default:
         REPORT_INSTRUCTION(options, dstType == ISA_TYPE_F || dstType == ISA_TYPE_DF || dstType == ISA_TYPE_HF || IsIntType(dstType), "%s has illegal dst type", ISA_Inst_Table[opcode].str);
@@ -1934,7 +1934,7 @@ void vISAVerifier::verifyInstructionLogi
             default:
             {
                 REPORT_INSTRUCTION(options,false,
-                         "All operands of logic instructions must be of integral type! opnd %d has unknow type %d",
+                         "All operands of logic instructions must be of integral type! opnd %d has unknown type %d",
                          i, (int)(opnd_type));
             }
         }
@@ -2238,7 +2238,7 @@ void vISAVerifier::verifyInstructionSamp
                 case 1:
                 case 2:
                 case 3: break;
-                default: REPORT_INSTRUCTION(options,false, "cntrl for CISA SAMPLER AVS intruction should be a "
+                default: REPORT_INSTRUCTION(options,false, "cntrl for CISA SAMPLER AVS instruction should be a "
                                                   "value 0-3 (8/16bit full/chrominance down sample).");
             }
 
@@ -2257,7 +2257,7 @@ void vISAVerifier::verifyInstructionSamp
                 case 1:
                 case 2:
                 case 3: break;
-                default: REPORT_INSTRUCTION(options,false, "execMode for CISA SAMPLER AVS intruction should "
+                default: REPORT_INSTRUCTION(options,false, "execMode for CISA SAMPLER AVS instruction should "
                                                   "be a value 0-3 (16x4, 8x4, 16x8, or 4x4).");
             }
 
@@ -4018,7 +4018,7 @@ void vISAVerifier::verifyKernelHeader()
         REPORT_HEADER(options,header->getSampler(i)->name_index < header->getStringCount(),
             "S%d's name index(%d) is not valid", i, header->getSampler(i)->name_index);
         REPORT_HEADER(options,header->getSampler(i)->num_elements <= COMMON_ISA_MAX_SAMPLER_SIZE,
-            "S%d's number of elements(%d) is not vaild", i, header->getSampler(i)->num_elements);
+            "S%d's number of elements(%d) is not valid", i, header->getSampler(i)->num_elements);
     }
 
     /// Verify surface.
--- a/visa/LocalScheduler/LocalScheduler_G4IR.cpp
+++ b/visa/LocalScheduler/LocalScheduler_G4IR.cpp
@@ -3156,7 +3156,7 @@ bool Node::hasConflict(Node* node2)
                     }
                     else
                     {
-                        //The same regsiter is reused in both SIMD8 instructions
+                        //The same register is reused in both SIMD8 instructions
                         prevInstRegs[1][i] = prevInstRegs[0][i];
                     }
                 }
@@ -3177,7 +3177,7 @@ bool Node::hasConflict(Node* node2)
             candidateNum++;
         }
     }
-    else    //For SIMD16 and SIMD32, if the GRF1 of src1 or src2 of inst 1 is GRF regsiter
+    else    //For SIMD16 and SIMD32, if the GRF1 of src1 or src2 of inst 1 is GRF register
     {
         if (prevInstRegs[1][1] != -1)
         {
--- a/visa/LoopAnalysis.cpp
+++ b/visa/LoopAnalysis.cpp
@@ -601,7 +601,7 @@ G4_BB* LoopDetection::getPreheader(Loop*
                 if (jipStr == headerLblStr ||
                     uipStr == headerLblStr)
                 {
-                    // dont create preheader for this loop as a predecessor
+                    // don't create preheader for this loop as a predecessor
                     // of header has SIMD CF in to loop header.
                     return nullptr;
                 }
--- a/visa/Optimizer.cpp
+++ b/visa/Optimizer.cpp
@@ -2063,7 +2063,7 @@ int Optimizer::optimization()
 //  converted to an if. Instead of creating a BB for each of the endif, we associate each endif with a label
 //  and emit them only at the very end.
 //
-//  For break and continue, UIP must be the lable directly attached to the while
+//  For break and continue, UIP must be the label directly attached to the while
 //  op. If not, create such a label
 //
 //  DO
@@ -9046,7 +9046,7 @@ bool Optimizer::foldPseudoAndOr(G4_BB* b
 
         if (!kernel.fg.builder->getIsKernel())
         {
-            // we dont allow a function to exit
+            // we don't allow a function to exit
             return;
         }
 
@@ -9464,7 +9464,7 @@ bool Optimizer::foldPseudoAndOr(G4_BB* b
         //  _label_ip_wa:
         //    add    dst     dst     32            // adjust dst to the next 2 instruction's ip
         //    ret    dst                           // jump to the next instruction
-        //    add    dst     -dst    call_target   // at this intruction dst is the ip value
+        //    add    dst     -dst    call_target   // at this instruction dst is the ip value
 
         uint32_t reg_num = add_with_ip->getDst()->getLinearizedStart() / kernel.numEltPerGRF<Type_UB>();
         uint32_t reg_off = add_with_ip->getDst()->getLinearizedStart() % kernel.numEltPerGRF<Type_UB>()
--- a/visa/Passes/LVN.cpp
+++ b/visa/Passes/LVN.cpp
@@ -400,7 +400,7 @@ bool LVN::canReplaceUses(INST_LIST_ITER
             // mov (8) V1<2>:d    V3
             // add (8) V2<1>:q    V2    V1<16;8,2>
             //
-            // => Dont replace V1<16;8,2> with V0<8;8,1> because it would make
+            // => Don't replace V1<16;8,2> with V0<8;8,1> because it would make
             // code HW non-conformant.
             canReplace = false;
         }
@@ -1071,7 +1071,7 @@ bool LVN::opndsMatch(T* opnd1, K* opnd2)
     }
     else
     {
-        // Not in SIMD CF so dont care
+        // Not in SIMD CF so don't care
     }
 
     if (match)
@@ -1366,7 +1366,7 @@ bool LVN::computeValue(G4_INST* inst, bo
     if (inst->getDst() && inst->getDst()->getTopDcl())
     {
         // Compute value for globals so we can insert it in LVN table.
-        // But we dont want to apply optimization on such instructions.
+        // But we don't want to apply optimization on such instructions.
         isGlobal = fg.globalOpndHT.isOpndGlobal(inst->getDst());
         isGlobal |= inst->getDst()->getTopDcl()->isOutput();
         isGlobal |= inst->getDst()->getTopDcl()->isInput();
@@ -1889,7 +1889,7 @@ void LVN::doLVN()
 
             // Compute value of current instruction
             // success is false when there is a float type-conversion mov
-            // that we dont implement, eg :hf->:f interpretation.
+            // that we don't implement, eg :hf->:f interpretation.
             success = computeValue(inst, false, canNegate, isGlobal, posVal, false, value);
             value.inst = inst;
             oldValue = value;
--- a/visa/Passes/MergeScalars.cpp
+++ b/visa/Passes/MergeScalars.cpp
@@ -43,7 +43,7 @@ static G4_Declare* getInputDeclare(
     // multiple of elementType, here just add additional checks to make sure this is the case.
     uint32_t offset = input->getRegVar()->getPhyRegOff() * input->getElemSize() + firstEltOffset;
     uint32_t eltBytes = TypeSize(eltType);
-    MUST_BE_TRUE((offset % eltBytes) == 0, "Offset shoule be mutiple of element size");
+    MUST_BE_TRUE((offset % eltBytes) == 0, "Offset should be multiple of element size");
     offset = offset / eltBytes;
     const char* name = builder.getNameString(builder.mem, 16, "InputR%d.%d", input->getRegVar()->getPhyReg()->asGreg()->getRegNum(), offset);
     G4_Declare* newInputDcl = builder.createDeclareNoLookup(name, G4_INPUT, (uint16_t)bundleSize, 1,
--- a/visa/ReduceExecSize.cpp
+++ b/visa/ReduceExecSize.cpp
@@ -132,7 +132,7 @@ HWConformity::fixDstAlignmentWithVectorI
 }
 
 // Do basic HW conformity check related to operand type and dst alignment before resucing execution size
-// to avoid spliting of the MOV inserted in this stage.
+// to avoid splitting of the MOV inserted in this stage.
 // This function is called for some instructions generated in later stages.
 bool HWConformity::fixInstOpndTypeAlign(INST_LIST_ITER i, G4_BB* bb)
 {
@@ -698,16 +698,16 @@ bool HWConformity::reduceExecSize(INST_L
     }
 
     // For inst with pred, condMod, or with mask in SIMDCF BB, we insert MOVs with nomask for src/dst
-    // to avoid instruction spliting. inserted MOVs may be split into multiple instructions.
+    // to avoid instruction splitting. inserted MOVs may be split into multiple instructions.
     // ATTN: We do not include sel here because the condMod generated by sel is never used.
     if (useFlag &&
         !(inst->opcode() == G4_sel && !(inst->getPredicate()) && inst->getCondMod()))
     {
         // if there is predicate or cond modifier, we keep the original instruction and
-        // perform spliting on new MOV instructions.
+        // perform splitting on new MOV instructions.
         if (!nullDst && !crossGRFDst && !goodOneGRFDst)
         {
-            // try to move 2-GRF src into 1GRF tmp to avoid spliting.
+            // try to move 2-GRF src into 1GRF tmp to avoid splitting.
             // this is unnecessary in non-SIMDCF/nonPred/nonCondMod cases because we can do compensation.
             for (int i = 0; i < inst->getNumSrc(); i++)
             {
@@ -827,7 +827,7 @@ bool HWConformity::reduceExecSize(INST_L
         // ==>
         // add (8) r6.0<1>:w r2.0<8;8,1>:d 0x1:w
         // mov (8) r5.3<1>:b r6.0<8;8,1>:w
-        // In some cases spliting the instruction generates the same number of instruction
+        // In some cases splitting the instruction generates the same number of instruction
         // without dependency, but needs more analysis.
         inst->setDest(insertMovAfter(iter, dst, dst->getType(), bb));
         if (builder.getOption(vISA_OptReport))
@@ -844,9 +844,9 @@ bool HWConformity::reduceExecSize(INST_L
 
     // only two kinds of instruction use ACC operands:
     // 1. instructions generated in ARCTAN intrinsic translation.
-    // they do not need spliting
+    // they do not need splitting
     // 2. instructions generated in MAC opt. there is a check to make
-    // sure only evenly spliting will happen to them.
+    // sure only evenly splitting will happen to them.
     if (useAcc)
     {
         evenlySplitInst(iter, bb);
--- a/visa/Rematerialization.cpp
+++ b/visa/Rematerialization.cpp
@@ -635,7 +635,7 @@ namespace vISA
                 float loopInstToTotalInstRatio = (float)getNumRematsInLoop() / (float)loopInstsBeforeRemat*100.0f;
                 if (rpe.getMaxRP() < rematRegPressure * 1.4f)
                 {
-                    // If max RPE is not very high, dont sink too many instructions in loop
+                    // If max RPE is not very high, don't sink too many instructions in loop
                     if(loopInstToTotalInstRatio > 1.75f)
                         return false;
                 }
@@ -690,7 +690,7 @@ namespace vISA
             if (srcOpnd->isSrcRegRegion())
             {
                 // If src operand base is non-regvar (eg, architecture
-                // register) then dont remat. Moving around such
+                // register) then don't remat. Moving around such
                 // registers could be dangerous.
                 if (!srcOpnd->getBase()->isRegVar())
                     return false;
@@ -722,7 +722,7 @@ namespace vISA
                     return false;
 
                 // If an instruction has physical registers allocated then
-                // dont optimize it.
+                // don't optimize it.
                 if (srcOpndRgn->getBase()->asRegVar()->getPhyReg() &&
                     !srcOpndTopDcl->isInput())
                     return false;
@@ -773,7 +773,7 @@ namespace vISA
                     auto extMsgOpnd = uniqueDefInst->getSrc(1);
                     MUST_BE_TRUE(extMsgOpnd->isSrcRegRegion() == true, "Unexpected src opnd for sampler");
 
-                    // Dont remat if sampler def is outside loop and use inside loop
+                    // Don't remat if sampler def is outside loop and use inside loop
                     if (onlyUseInLoop)
                         return false;
 
@@ -1004,7 +1004,7 @@ namespace vISA
                 auto src0Rgn = uniqueDef->first->getSrc(0)->asSrcRegRegion();
                 auto src0TopDcl = src0Rgn->getTopDcl();
                 auto ops = operations.find(src0TopDcl);
-                MUST_BE_TRUE(ops != operations.end(), "Didnt find record in map");
+                MUST_BE_TRUE(ops != operations.end(), "Didn't find record in map");
                 MUST_BE_TRUE((*ops).second.numUses == 1, "Expecting src0 to be used only in sampler");
 
                 G4_Declare* newSrc0Dcl = nullptr;
@@ -1024,7 +1024,7 @@ namespace vISA
 
                         auto dupOp = headerDefInst->cloneInst();
                         auto headerDefDst = headerDefInst->getDst();
-                        assert(!headerDefDst->isIndirect()); // we dont allow send header to be defined indirectly
+                        assert(!headerDefDst->isIndirect()); // we don't allow send header to be defined indirectly
                         dupOp->setDest(kernel.fg.builder->createDst(
                             newSrc0Dcl->getRegVar(), headerDefDst->getRegOff(), headerDefDst->getSubRegOff(),
                             headerDefDst->getHorzStride(), headerDefDst->getType()));
--- a/visa/SpillCleanup.cpp
+++ b/visa/SpillCleanup.cpp
@@ -76,7 +76,7 @@ void CoalesceSpillFills::copyToOldFills(
     INST_LIST_ITER f, G4_BB* bb, int srcCISAOff)
 {
     // Copy data from coalesced fill in to older fills.
-    // This way we dont carry entire coalesced payload
+    // This way we don't carry entire coalesced payload
     // till last fill.
     for (auto oldFill : indFills)
     {
@@ -319,7 +319,7 @@ bool CoalesceSpillFills::fillHeuristic(s
     }
 
     // Iterate over coalescable fills and ensure all rows of a variable
-    // are fill candidates. If not, then dont fill. This helps cases like,
+    // are fill candidates. If not, then don't fill. This helps cases like,
     // #1 FILL_V10(0,0) <-- load 0x10 ... (4 GRFs)
     // #2 FILL_V10(4,0) <-- load 0x14 ... (1 GRF)
     // #3 send ... FILL_V10(0,0)   ... (use 3 GRFs of FILL_V10)
@@ -391,7 +391,7 @@ bool CoalesceSpillFills::fillHeuristic(s
         if (bits[0] != bits[1] &&
             bits[2] != bits[3])
         {
-            // Dont coalesce patterns like
+            // Don't coalesce patterns like
             // 1010, 0101
             return false;
         }
@@ -611,7 +611,7 @@ void CoalesceSpillFills::keepConsecutive
                     auto curInstDstTopDcl = (*(*spillIt))->getSrc(1)->getTopDcl();
                     // Check whether current inst's topdcl was spilled in a send.
                     // If it was and first instruction in instList wasnt then
-                    // dont consider current instruction as coalescing candidate.
+                    // don't consider current instruction as coalescing candidate.
                     if (!firstSpillFromSend &&
                         sendDstDcl.find(curInstDstTopDcl) != sendDstDcl.end())
                     {
@@ -817,7 +817,7 @@ INST_LIST_ITER CoalesceSpillFills::analy
         instList = origInstList;
         instList.pop_front();
 #if 0
-        printf("Fill heuristic didnt agree to coalescing\n");
+        printf("Fill heuristic didn't agree to coalescing\n");
 #endif
     }
 
@@ -1042,7 +1042,7 @@ void CoalesceSpillFills::fills()
             if (splitInsts.find(inst) != splitInsts.end())
             {
                 // if inst was emitted by loop split transformation,
-                // then dont optimize it. such instructions are
+                // then don't optimize it. such instructions are
                 // emitted in loop preheader/loop exit. if a split
                 // variable spills, we need to erase all fills and
                 // spills emitted for that split. if we coalesce
@@ -1772,7 +1772,7 @@ void CoalesceSpillFills::spillFillCleanu
                         unsigned int pRowStart, pNumRows;
                         getScratchMsgInfo(pInst, pRowStart, pNumRows);
 
-                        // If any def of src1 dcl is found then dont
+                        // If any def of src1 dcl is found then don't
                         // consider this write for optimization. Its
                         // value in memory could be different than
                         // one held in variable.
--- a/visa/SpillCode.h
+++ b/visa/SpillCode.h
@@ -47,7 +47,7 @@ class SpillManager
 
     unsigned int currCISAOffset;
 
-    // store spilled operands that dont need RMW for spills
+    // store spilled operands that don't need RMW for spills
     std::unordered_set<G4_Operand*> noRMWNeeded;
 
     void genRegMov(G4_BB* bb,
--- a/visa/SpillManagerGMRF.cpp
+++ b/visa/SpillManagerGMRF.cpp
@@ -1665,7 +1665,7 @@ SpillManagerGRF::createMRangeDeclare(
     if (useScratchMsg_)
     {
         assert(payloadHeaderHeight != DWORD_PAYLOAD_HEADER_MAX_HEIGHT);
-        // When using scratch msg descriptor we dont need to use a
+        // When using scratch msg descriptor we don't need to use a
         // separate GRF for payload. Source operand of send can directly
         // use r0.0.
         return builder_->getBuiltinR0();
@@ -3119,7 +3119,7 @@ bool SpillManagerGRF::checkUniqueDefAlig
 }
 
 // This function checks whether each spill dst region requires a read-modify-write operation
-// when inserting spill code. Dominator/unique defs dont require redundant read operation.
+// when inserting spill code. Dominator/unique defs don't require redundant read operation.
 // Dst regions that do not need RMW are added to a set. This functionality isnt needed for
 // functional correctness. This function is executed before inserting spill code because
 // we need all dst regions of dcl available to decide whether read is redundant. If this is
@@ -3449,7 +3449,7 @@ void SpillManagerGRF::insertSpillRangeCo
                 {
                     // srcRegion is a split var temp
                     // this is a copy in either preheader or loop exit.
-                    // add it to list so we know it shouldnt be optimized
+                    // add it to list so we know it shouldn't be optimized
                     // by spill cleanup.
                     for (auto addedInst : builder_->instList)
                     {
@@ -3509,7 +3509,7 @@ void SpillManagerGRF::insertFillGRFRange
         // if inst is:
         // (W) mov (8|M0) SPLIT1    V10
         //
-        // and SPLIT1 is marked as spilled then dont insert spill code for it.
+        // and SPLIT1 is marked as spilled then don't insert spill code for it.
         // V10 is guaranteed to be spilled already so there is no point spilling
         // SPLIT1. we simply remove above instruction and any fill emitted to load
         // V10 and return.
@@ -3584,7 +3584,7 @@ void SpillManagerGRF::insertFillGRFRange
                 {
                     // dstRegion is a split var temp
                     // this is a copy in either preheader or loop exit.
-                    // add it to list so we know it shouldnt be optimized
+                    // add it to list so we know it shouldn't be optimized
                     // by spill cleanup.
                     for (auto addedInst : builder_->instList)
                     {
@@ -3875,7 +3875,7 @@ void SpillManagerGRF::insertAddrTakenSpi
                 // however, this sets a bit in liveness bit-vector that
                 // causes the temp variable to be marked as live-out from
                 // that BB. A general fix should treat address taken variables
-                // more accurately wrt liveness so they dont escape via
+                // more accurately wrt liveness so they don't escape via
                 // unfeasible paths.
                 //pointsToAnalysis.addFillToPointsTo(bbid, var, temp->getRegVar());
             }
@@ -4074,7 +4074,7 @@ void SpillManagerGRF::insertAddrTakenLSS
                 // however, this sets a bit in liveness bit-vector that
                 // causes the temp variable to be marked as live-out from
                 // that BB. A general fix should treat address taken variables
-                // more accurately wrt liveness so they dont escape via
+                // more accurately wrt liveness so they don't escape via
                 // unfeasible paths.
                 //pointsToAnalysis.addFillToPointsTo(bbid, var, temp->getRegVar());
             }
@@ -4933,7 +4933,7 @@ void GlobalRA::saveRestoreA0(G4_BB * bb)
 
     auto isPrologOrEpilog = [this](G4_INST* inst)
     {
-        // a0 is a caller save register. Dont save/restore it if it is used in callee save/restore sequence or
+        // a0 is a caller save register. Don't save/restore it if it is used in callee save/restore sequence or
         // for frame descriptor spill instruction.
         if (inst == kernel.fg.builder->getFDSpillInst())
             return false;
--- a/visa/VarSplit.cpp
+++ b/visa/VarSplit.cpp
@@ -66,7 +66,7 @@ void VarSplitPass::verify()
             }
         }
 
-        MUST_BE_TRUE(found, "Didnt find child dcl");
+        MUST_BE_TRUE(found, "Didn't find child dcl");
         return childLbRb;
     };
 
@@ -78,12 +78,12 @@ void VarSplitPass::verify()
             if (inst->isSplitIntrinsic())
             {
                 // ensure this is split mov instruction
-                MUST_BE_TRUE(inst->isSplitIntrinsic(), "Didnt expect new non-split intrinsic instruction");
+                MUST_BE_TRUE(inst->isSplitIntrinsic(), "Didn't expect new non-split intrinsic instruction");
 
                 // verify that split instruction's dst, src(0) is correct
                 splitDcls.insert(inst->getDst()->getTopDcl());
 
-                MUST_BE_TRUE(!inst->getSrc(0)->getTopDcl()->getAddressed(), "Shouldnt split indirectly addressed variable");
+                MUST_BE_TRUE(!inst->getSrc(0)->getTopDcl()->getAddressed(), "Shouldn't split indirectly addressed variable");
 
                 auto origSrc0 = inst->getSrc(0)->asSrcRegRegion();
                 auto origLb = origSrc0->getLeftBound();
@@ -395,7 +395,7 @@ void VarSplitPass::findSplitCandidates()
 
         if (item.second.srcs.size() > 0)
         {
-            // Dont emit split if all uses are closeby
+            // Don't emit split if all uses are closeby
             unsigned int idx = instId[item.second.srcs.front().first->getInst()];
             bool split = true;
             if (item.second.srcs.size() > 1)
@@ -422,7 +422,7 @@ void VarSplitPass::findSplitCandidates()
                 }
             }
 
-            // dont split if def-last first use distance <= 8
+            // don't split if def-last first use distance <= 8
             if (split &&
                 (instId[item.second.srcs.back().first->getInst()] - instId[item.second.def.first->getInst()]) <= 8)
                 split = false;
@@ -494,7 +494,7 @@ void VarSplitPass::split()
             splitParentDcl.insert(std::make_pair(splitDcl, dstDcl));
             splitChildren[dstDcl].push_back(splitDcl);
 
-            // If this part of dcl is never used in code, then dont create split intrinsic inst for it
+            // If this part of dcl is never used in code, then don't create split intrinsic inst for it
             if (!item.second.isPartDclUsed(lb, rb))
             {
                 unusedDcls.insert(splitDcl);
@@ -553,7 +553,7 @@ void VarSplitPass::split()
             auto item = getSplitDcl(lb, rb);
             auto item_lb = std::get<0>(item);
             auto dcl = std::get<2>(item);
-            MUST_BE_TRUE(dcl, "Didnt find split dcl");
+            MUST_BE_TRUE(dcl, "Didn't find split dcl");
 
             unsigned int regNum = (lb - item_lb) / kernel.numEltPerGRF<Type_UB>();
 
@@ -1432,7 +1432,7 @@ std::vector<Loop*> LoopVarSplit::getLoop
     // prune list of loops
     // 1. loops are stored in descending order of max reg pressure
     // 2. apply cost heuristic to decide if variable should be split at a loop
-    // 3. once split at a loop, dont split at any parent or nested loop
+    // 3. once split at a loop, don't split at any parent or nested loop
     //
     // Example:
     //
--- a/visa/iga/IGAExe/iga_main.cpp
+++ b/visa/iga/IGAExe/iga_main.cpp
@@ -502,7 +502,7 @@ extern "C" int iga_main(int argc, const
     xGrp.defineFlag(
         "print-ldst",
         nullptr,
-        "enables load/store pseudo intructions where possible",
+        "enables load/store pseudo instructions where possible",
         "Send instructions are emitted as load/store instructions",
         opts::OptAttrs::ALLOW_UNSET,
         baseOpts.printLdSt);
--- a/visa/iga/IGALibrary/Backend/Messages/MessageDecoderOther.cpp
+++ b/visa/iga/IGALibrary/Backend/Messages/MessageDecoderOther.cpp
@@ -743,7 +743,7 @@ static void decodeSendMessage(
             break;
         case 0x1D:
             symbol = "sample_ld_mcs";
-            desc = "sample load mcs auxilary data";
+            desc = "sample load mcs auxiliary data";
             params = 4;
             break;
         case 0x1E:
--- a/visa/iga/IGALibrary/api/kv.h
+++ b/visa/iga/IGALibrary/api/kv.h
@@ -366,7 +366,7 @@ IGA_API uint32_t kv_get_opcode(const kv_
 IGA_API kv_status_t kv_get_subfunction(const kv_t *kv, int32_t pc, uint32_t* subfunc);
 
 /*
- * This function returns if intruction has destination.
+ * This function returns if instruction has destination.
  */
 IGA_API int32_t kv_get_has_destination(const kv_t *kv, int32_t pc);
 
--- a/IGC/AdaptorOCL/OCL/sp/sp_g8.cpp
+++ b/IGC/AdaptorOCL/OCL/sp/sp_g8.cpp
@@ -2006,7 +2006,7 @@ RETVAL CGen8OpenCLStateProcessor::Create
 
     }
 
-    // Patch for Execution Enivronment
+    // Patch for Execution Environment
     if( retValue.Success )
     {
         iOpenCL::SPatchExecutionEnvironment patch;
--- a/3d/common/iStdLib/FastMask.h
+++ b/3d/common/iStdLib/FastMask.h
@@ -375,7 +375,7 @@ void CFastMaskSetType::ClearBits( void )
         index = m_SetList[i];
 
         // the user can un-set bits prior to calling clear and we need to ensure
-        //  that we dont try to change those entries as they dont matter and could
+        //  that we don't try to change those entries as they don't matter and could
         //  corrupt the heap
         if( index != m_Key )
         {
--- a/IGC/AdaptorOCL/SPIRV/SPIRVReader.cpp
+++ b/IGC/AdaptorOCL/SPIRV/SPIRVReader.cpp
@@ -2596,7 +2596,7 @@ SPIRVToLLVM::transCmpInst(SPIRVValue* BV
 
 bool
 SPIRVToLLVM::postProcessOCL() {
-  // I think we dont need it
+  // I think we don't need it
   std::vector <Function*> structFuncs;
   for (auto& F : M->functions())
   {
--- a/IGC/BiFModule/Implementation/atomics.cl
+++ b/IGC/BiFModule/Implementation/atomics.cl
@@ -138,7 +138,7 @@ extern __constant int __UseNativeFP64Glo
 // will still go down the coherant pipeline.  The 2 L3$ pipes do not guarentee order of operations between
 // themselves.
 
-// Since we dont have specialized atomic load/store HDC message we're using atomic_or( a, 0x0 ) to emulate
+// Since we don't have specialized atomic load/store HDC message we're using atomic_or( a, 0x0 ) to emulate
 // an atomic load since it does not modify the in memory value and returns the 'old' value. atomic store
 // can be implemented with an atomic_exchance with the return value ignored.
 
--- a/IGC/Compiler/CISACodeGen/CShader.cpp
+++ b/IGC/Compiler/CISACodeGen/CShader.cpp
@@ -2785,7 +2785,7 @@ unsigned int CShader::EvaluateSIMDConstE
     {
         return (unsigned int)constValue->getZExtValue();
     }
-    IGC_ASSERT_MESSAGE(0, "unknow SIMD constant expression");
+    IGC_ASSERT_MESSAGE(0, "unknown SIMD constant expression");
     return 0;
 }
 
--- a/IGC/Compiler/CISACodeGen/DebugInfo.cpp
+++ b/IGC/Compiler/CISACodeGen/DebugInfo.cpp
@@ -394,7 +394,7 @@ void DebugInfoData::markOutputVar(CShade
         // So that finalizer can extend their liveness to end of the program.
         // This will help debugger examine their values anywhere in the code till they
         // are in scope. However, emit "Output" attribute when -g and -cl-opt-disable
-        // are both passed -g by itself shouldnt alter generated code.
+        // are both passed -g by itself shouldn't alter generated code.
         if (static_cast<OpenCLProgramContext*>(pShader->GetContext())->m_InternalOptions.KernelDebugEnable ||
             pShader->GetContext()->getModuleMetaData()->compOpt.OptDisable)
         {
@@ -542,7 +542,7 @@ void DebugInfoData::markOutputVars(const
             if (m_pShader->GetContext()->getModuleMetaData()->compOpt.OptDisable)
             {
                 // Emit "Output" attribute only when -g and -cl-opt-disable are both passed
-                // -g by itself shouldnt alter generated code
+                // -g by itself shouldn't alter generated code
                 m_pShader->GetEncoder().GetVISAKernel()->AddAttributeToVar(pVar->visaGenVariable[0], "Output", 0, nullptr);
                 if (m_pShader->m_dispatchSize == SIMDMode::SIMD32 && pVar->visaGenVariable[1])
                 {
--- a/IGC/Compiler/CISACodeGen/MemOpt.cpp
+++ b/IGC/Compiler/CISACodeGen/MemOpt.cpp
@@ -598,7 +598,7 @@ bool MemOpt::mergeLoad(LoadInst* Leading
         if (!NextLoad->isSimple())
             break;
 
-        // If we get an ordered load (such as a cst_seq atomic load/store) dont
+        // If we get an ordered load (such as a cst_seq atomic load/store) don't
         // merge.
         if (!NextLoad->isUnordered())
             break;
@@ -932,7 +932,7 @@ bool MemOpt::mergeStore(StoreInst* Leadi
         if (!NextStore->isSimple())
             break;
 
-        // If we get an ordered store (such as a cst_seq atomic load/store) dont
+        // If we get an ordered store (such as a cst_seq atomic load/store) don't
         // merge.
         if (!NextStore->isUnordered())
             break;
--- a/IGC/Compiler/CISACodeGen/PatternMatchPass.cpp
+++ b/IGC/Compiler/CISACodeGen/PatternMatchPass.cpp
@@ -1161,7 +1161,7 @@ namespace IGC
 
             if (IGCMetrics::IGCMetric::isMetricFuncCall(&I))
             {
-                // dont do anything with metrics calls
+                // don't do anything with metrics calls
                 return;
             }
 
@@ -5005,7 +5005,7 @@ namespace IGC
                 if (llvm::ConstantInt * simDOffSetInst = llvm::dyn_cast<llvm::ConstantInt>(binaryInst->getOperand(1)))
                 {
                     uint shiftFactor = int_cast<uint>(simDOffSetInst->getZExtValue());
-                    //Check to make sure we dont end up with an invalid Vertical Stride.
+                    //Check to make sure we don't end up with an invalid Vertical Stride.
                     //Only 1, 2, 4, 8, 16 are supported.
                     if (shiftFactor <= 4)
                         verticalStride = (1U << shiftFactor);
--- a/IGC/Compiler/CISACodeGen/VertexShaderLowering.cpp
+++ b/IGC/Compiler/CISACodeGen/VertexShaderLowering.cpp
@@ -50,7 +50,7 @@ namespace IGC
 
     bool VertexShaderLowering::runOnFunction(llvm::Function& F)
     {
-        // VS lowering only applies to entry function. Non-entry funtions
+        // VS lowering only applies to entry function. Non-entry functions
         // are emulation functions that do not need to be lowered!
         MetaDataUtils* pMdUtils = nullptr;
         pMdUtils = getAnalysis<MetaDataUtilsWrapper>().getMetaDataUtils();
@@ -283,7 +283,7 @@ namespace IGC
                             {
                                 auto useIterBegin = inst->user_begin(), useIterEnd = inst->user_end();
 
-                                // if one use of instance_id with constant buffer is found we dont need to look for more
+                                // if one use of instance_id with constant buffer is found we don't need to look for more
                                 bool foundConstantBufferAccessedWithInstanceID = false;
                                 while ((useIterBegin != useIterEnd) &&
                                     !foundConstantBufferAccessedWithInstanceID)
--- a/IGC/Compiler/CISACodeGen/helper.cpp
+++ b/IGC/Compiler/CISACodeGen/helper.cpp
@@ -1268,7 +1268,7 @@ namespace IGC
                 bufType = DecodeAS4GFXResource(as, directIndexing, textureIdx);
                 if (bufType == UAV)
                 {
-                    // dont do any clustering on read/write images
+                    // don't do any clustering on read/write images
                     textureIdx = -1;
                 }
             }
--- a/IGC/Compiler/CodeGenPublicEnums.h
+++ b/IGC/Compiler/CodeGenPublicEnums.h
@@ -261,7 +261,7 @@ namespace IGC
         ROUND_TO_NEGATIVE,
         ROUND_TO_ZERO,
 
-        ROUND_TO_ANY   // dont care
+        ROUND_TO_ANY   // don't care
     };
 
 
--- a/IGC/Compiler/CustomLoopOpt.hpp
+++ b/IGC/Compiler/CustomLoopOpt.hpp
@@ -27,7 +27,7 @@ namespace IGC
     ///////////////////////////////////////////////////////////////////////////
     /// Enforce a single latch for every loop header. This needs to be ran before
     /// LLVM Loop canonicalization pass as LLVM loop simplification pass sometimes
-    /// decides to spilt the loop. Spliting the loop may cause functional issues
+    /// decides to split the loop. Splitting the loop may cause functional issues
     /// in case of barriers being used and it may cause extra SIMD divergence causing
     /// performance degradation
     llvm::FunctionPass* createLoopCanonicalization();
--- a/IGC/Compiler/Optimizer/OpenCLPasses/AggregateArguments/AggregateArguments.cpp
+++ b/IGC/Compiler/Optimizer/OpenCLPasses/AggregateArguments/AggregateArguments.cpp
@@ -233,7 +233,7 @@ bool ResolveAggregateArguments::runOnFun
         StructType* structType = cast<StructType>(arg->getType()->getPointerElementType());
 
         // LLVM assumes the caller has create an alloca and pushed the contents
-        // of the struct on the stack.  Since we dont have a caller, create
+        // of the struct on the stack.  Since we don't have a caller, create
         // the alloca here.
         std::string allocaName = std::string(arg->getName()) + "_alloca";
         llvm::AllocaInst* base = irBuilder.CreateAlloca(structType, 0, allocaName);
--- a/IGC/Compiler/Optimizer/OpenCLPasses/ProgramScopeConstants/ProgramScopeConstantAnalysis.cpp
+++ b/IGC/Compiler/Optimizer/OpenCLPasses/ProgramScopeConstants/ProgramScopeConstantAnalysis.cpp
@@ -167,7 +167,7 @@ bool ProgramScopeConstantAnalysis::runOn
 
         if (initializer->isZeroValue())
         {
-            // For zero initialized values, we dont need to copy the data, just tell driver how much to allocate
+            // For zero initialized values, we don't need to copy the data, just tell driver how much to allocate
             // However, if it's used as a pointer value, we need to do patching and therefore cannot defer the offset calculation
             bool hasPointerUser = false;
             for (auto UI : globalVar->users())
--- a/IGC/Compiler/PromoteResourceToDirectAS.cpp
+++ b/IGC/Compiler/PromoteResourceToDirectAS.cpp
@@ -530,7 +530,7 @@ void PromoteResourceToDirectAS::PromoteB
 
     // Vulkan encodes address space differently, with the reserve bits set.
     // TODO: Investigate how addrspace is encoded in Vulkan,
-    // for now skip promoting if it's an address space we dont recognize.
+    // for now skip promoting if it's an address space we don't recognize.
     if ((addrSpace & 0xFFC00000) != 0x0)
     {
         return;
--- a/IGC/DebugInfo/DwarfDebug.cpp
+++ b/IGC/DebugInfo/DwarfDebug.cpp
@@ -1659,7 +1659,7 @@ void DwarfDebug::collectVariableInfo(
         RegVar = prevRegVar;
 
       // Conditions below decide whether we want to emit location to debug_loc
-      // or inline it in the DIE. To inline in DIE, we simply dont emit anything
+      // or inline it in the DIE. To inline in DIE, we simply don't emit anything
       // here and continue the loop.
       bool needsCallerSave =
           !m_pModule->getCompileUnit(*decodedDbg)->cfi.callerSaveEntry.empty();
--- a/IGC/DebugInfo/VISAModule.cpp
+++ b/IGC/DebugInfo/VISAModule.cpp
@@ -191,7 +191,7 @@ const std::string &VISAModule::GetTarget
 
 bool VISAModule::IsExecutableInst(const llvm::Instruction &inst) {
   // Return false if inst is dbg info intrinsic or if it is
-  // catch all intrinsic. In both of these cases, we dont want
+  // catch all intrinsic. In both of these cases, we don't want
   // to emit associated debug loc since there is no machine
   // code generated for them.
   if (IsCatchAllIntrinsic(&inst))
--- a/IGC/VectorCompiler/lib/GenXCodeGen/GenXCategory.cpp
+++ b/IGC/VectorCompiler/lib/GenXCodeGen/GenXCategory.cpp
@@ -731,7 +731,7 @@ Instruction *GenXCategory::createConvers
   // and this isn't an address conversion, use the operand for that
   // intrinsic call directly rather than using the result of the intrinsic.
   // This helps the jitter to generate better code when surface constants
-  // are used in send intructions.
+  // are used in send instructions.
   if (Cat != vc::RegCategory::Address) {
     if (GenXIntrinsic::getGenXIntrinsicID(V) == GenXIntrinsic::genx_constanti)
       V = cast<CallInst>(V)->getArgOperand(0);
--- a/visa/DebugInfo.cpp
+++ b/visa/DebugInfo.cpp
@@ -895,7 +895,7 @@ unsigned int populateMapDclName(VISAKern
     for (uint32_t ctr = 0; ctr < kernel->getGenVarCount(); ctr++)
     {
         // Pre-defined gen vars are included in this list,
-        // but we dont want to emit them to debug info.
+        // but we don't want to emit them to debug info.
         if (kernel->getGenVar((unsigned int)ctr)->index >= kernel->getNumPredVars())
         {
             dclList.push_back(kernel->getGenVar((unsigned int)ctr));
@@ -1524,7 +1524,7 @@ void emitDataCallFrameInfo(VISAKernelImp
 }
 
 // compilationUnits has 1 kernel and stack call functions
-// referenced by it. In case stack call functions dont
+// referenced by it. In case stack call functions don't
 // exist in input, it only has a kernel.
 template<class T>
 void emitData(std::list<VISAKernelImpl*>& compilationUnits, T t)
--- a/visa/G4Instruction.h
+++ b/visa/G4Instruction.h
@@ -141,7 +141,7 @@ HANDLE_INST(pseudo_exit,  0, 0, InstType
 HANDLE_INST(pseudo_fc_call, 1, 1, InstTypeFlow, GENX_BDW, ATTR_NONE)
   // pseudo_fc_ret are generated for return statements from callable kernels.
   // This has to be done because for kernels, we convert VISA ret instruction
-  // to EOT. But for callable kernels, we dont want to emit EOT because they
+  // to EOT. But for callable kernels, we don't want to emit EOT because they
   // may have to return to a top-level kernel. Only top-level kernel will
   // have VISA ret lowered to EOT.
 HANDLE_INST(pseudo_fc_ret, 1, 0, InstTypeFlow, GENX_BDW, ATTR_NONE)
--- a/visa/LocalRA.cpp
+++ b/visa/LocalRA.cpp
@@ -3225,7 +3225,7 @@ void LinearScan::coalesceSplit(LocalLive
         }
     }
 
-    // now free phy regs of split that dont have an intrinsic split emitted, ie unused
+    // now free phy regs of split that don't have an intrinsic split emitted, ie unused
     // rows of parent dcl.
     unsigned int idx;
     lr->getFirstRef(idx);
--- a/visa/PhyRegUsage.cpp
+++ b/visa/PhyRegUsage.cpp
@@ -938,7 +938,7 @@ PhyRegUsage::PhyReg PhyRegUsage::findGRF
             {
                 if (phyReg.reg == -1)
                 {
-                    // favor partially allocated GRF first so dont
+                    // favor partially allocated GRF first so don't
                     // return this assignment yet
                     phyReg.reg = idx;
                     phyReg.subreg = 0;
--- a/visa/RegAlloc.cpp
+++ b/visa/RegAlloc.cpp
@@ -2041,7 +2041,7 @@ void LivenessAnalysis::computeGenKilland
                     while ((grf = pointsToAnalysis.getPointsTo(topdcl->getRegVar(), idx++)) != NULL)
                     {
                         // grf is a variable that src potentially points to
-                        // since we dont know exactly which part of grf is sourced
+                        // since we don't know exactly which part of grf is sourced
                         // assume entire grf is sourced
                         // Also add grf to the gen set as it may be potentially used
                         unsigned int id = grf->getId();
@@ -2191,7 +2191,7 @@ void LivenessAnalysis::computeGenKilland
                     topdclLR->isLiveRangeLocal() &&
                     (!topdcl->isInput()) &&
                     topdclLR->getFirstRef(first) == i)) &&
-                    // If single inst writes whole region then dont insert pseudo_kill
+                    // If single inst writes whole region then don't insert pseudo_kill
                     writeWholeRegion(bb, i, dst, fg.builder->getOptions()) == false)
                 {
                     bool foundKill = false;
@@ -2255,7 +2255,7 @@ void LivenessAnalysis::computeGenKilland
                     (topdclLR = gra.getLocalLR(topdcl)) &&
                         topdclLR->isLiveRangeLocal() &&
                         topdclLR->getFirstRef(first) == i)) &&
-                        // If single inst writes whole region then dont insert pseudo_kill
+                        // If single inst writes whole region then don't insert pseudo_kill
                         writeWholeRegion(bb, i, flagReg) == false)
                 {
                     // All bytes of dst written at this point, so this is a good place to insert
--- a/visa/SplitAlignedScalars.cpp
+++ b/visa/SplitAlignedScalars.cpp
@@ -512,7 +512,7 @@ void SplitAlignedScalars::run()
                             gra.addEUFusionNoMaskWAInst(bb, copy);
                         }
 
-                        // this copy shouldnt be rematerialized
+                        // this copy shouldn't be rematerialized
                         gra.addNoRemat(copy);
 
                         numMovsAdded++;
--- a/visa/VisaToG4/TranslateMisc.cpp
+++ b/visa/VisaToG4/TranslateMisc.cpp
@@ -516,7 +516,7 @@ int IR_Builder::translateVISALifetimeIns
             nullptr, nullptr, InstOpt_WriteEnable, true);
     }
 
-    // We dont treat lifetime.end specially for now because lifetime.start
+    // We don't treat lifetime.end specially for now because lifetime.start
     // is expected to halt propagation of liveness upwards. lifetime.start
     // would prevent loop local variables/sub-rooutine local variables
     // from being live across entire loop/sub-routine.
